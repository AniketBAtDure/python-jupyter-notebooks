{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "29b9bd1d-766f-4422-ad96-de0accc1ce58"
    }
   },
   "source": [
    "# Emotions From Images: Convolutional Neural Network with CNTK\n",
    "\n",
    "This notebook is based and much information is from the CNTK tutorial [here](https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html).\n",
    "\n",
    "In this tutorial we will train a Convolutional Neural Network (CNN) on facial expression image data. This notebook provides the recipe using the Python API.\n",
    "\n",
    "**Problem**:\n",
    "In this exercise we will work with an emotions dataset, comprising of grayscale images of either happy or sad faces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "138d1a78-02e2-4bd6-a20e-07b83f303563"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "C.cntk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Format** The data is stored on our local machine in the CNTK CTF format.  The CTF format is a simple text format that contains a set of samples with each sample containing a set of named fields and their data.  For MNIST data, each sample contains 2 fields: labels and feature, formatted as:\n",
    "\n",
    "    |labels 0 0 0 1 0 0 0 0 0 0 |features 0 255 0 123 ... \n",
    "                                                  (784 integers each representing a pixel gray level)\n",
    "    \n",
    "In this tutorial we are going to use the image pixels corresponding to the integer stream named \"features\". We define a `create_reader` function to read the training and test data using the [CTF deserializer](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.CTFDeserializer). . \n",
    "\n",
    "The labels are [1-hot](https://en.wikipedia.org/wiki/One-hot) encoded (the label representing the output class of 3  becomes `0001000000` since we have 10 classes for the 10 possible digits), where the first index corresponds to digit `0` and the last one corresponds to digit `9`.\n",
    "\n",
    "![mnist-label](https://www.cntk.ai/jup/cntk103a_onehot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "    \n",
    "    ctf = C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "          labels=C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n",
    "          features=C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)))\n",
    "                          \n",
    "    return C.io.MinibatchSource(ctf,\n",
    "        randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is /data\n"
     ]
    }
   ],
   "source": [
    "# Ensure the training and test data is available for this tutorial.\n",
    "# We search in two locations in the toolkit for the cached MNIST data set.\n",
    "\n",
    "data_found=False # A flag to indicate if train/test data found in local cache\n",
    "for data_dir in [os.path.join(os.path.sep + \"data\")]:\n",
    "    \n",
    "    train_file=os.path.join(data_dir, \"Emotions-48x48-train_cntk_text.txt\")\n",
    "    test_file=os.path.join(data_dir, \"Emotions-48x48-test_cntk_text.txt\")\n",
    "    \n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found=True\n",
    "        break\n",
    "        \n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing CNTK 103 Part A\")\n",
    "    \n",
    "print(\"Data directory is {0}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Emotions-48x48-test_cntk_text.txt\n"
     ]
    }
   ],
   "source": [
    "print(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a basic 3-layer CNN with the layers module \n",
    "# Ref:  https://cntk.ai/pythondocs/layerref.html\n",
    "\n",
    "# def create_model(features):\n",
    "#     with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "#             h = features\n",
    "#             h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "#                                        num_filters=8, \n",
    "#                                        strides=(2,2), \n",
    "#                                        pad=True, \n",
    "#                                        name='first_conv')(h)\n",
    "#             h = C.layers.Convolution2D(filter_shape=(5,5),\n",
    "#                                        num_filters=16,\n",
    "#                                        strides=(1,1), \n",
    "#                                        pad=True, \n",
    "#                                        name='second_conv')(h)\n",
    "#             h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "#                                        num_filters=16,\n",
    "#                                        strides=(2,2), \n",
    "#                                        pad=True, \n",
    "#                                        name='thrid_conv')(h)\n",
    "#             r = C.layers.Dense(num_output_classes, \n",
    "#                                activation=None, \n",
    "#                                name='classify')(h)\n",
    "#             return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a CNN with pooling with the layers module \n",
    "# Ref:  https://cntk.ai/pythondocs/layerref.html#maxpooling-averagepooling\n",
    "\n",
    "# def create_model(features):\n",
    "#     with C.layers.default_options(init=C.glorot_uniform(), activation=C.leaky_relu):\n",
    "#             h = features\n",
    "#             h = C.layers.Convolution2D(filter_shape=(5,5), # shape of receptive field\n",
    "#                                        num_filters=8, \n",
    "#                                        strides=(1,1), \n",
    "#                                        pad=True, name='first_conv')(h)\n",
    "#             h = C.layers.AveragePooling(filter_shape=(2,2),   \n",
    "#                            strides=1,\n",
    "#                            pad=True,\n",
    "#                            name='first_pooling')(h)\n",
    "#             h = C.layers.Convolution2D(filter_shape=(5,5),\n",
    "#                                        num_filters=16,\n",
    "#                                        strides=(1,1), \n",
    "#                                        pad=True, name='second_conv')(h)\n",
    "#             h = C.layers.MaxPooling(filter_shape=(2,2),\n",
    "#                            strides=1,\n",
    "#                            pad=True,\n",
    "#                            name='second_pooling')(h)\n",
    "#             h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "#                                        num_filters=16,\n",
    "#                                        strides=(2,2), \n",
    "#                                        pad=True, name='third_conv')(h)\n",
    "#             h = C.layers.MaxPooling(filter_shape=(2,2),\n",
    "#                            strides=1,\n",
    "#                            pad=True,\n",
    "#                            name='third_pooling')(h)\n",
    "#             r = C.layers.Dense(num_output_classes, activation=None, \n",
    "#                                name='classify')(h)\n",
    "#             return r\n",
    "        \n",
    "# With MaxPooling as the first pooling layer:  Average test error: 31.79%\n",
    "# With AveragePooling as the first pooling layer:  Average test error: 30.23%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a CNN with pooling with the layers module and using the Sequential shortcut\n",
    "# Ref:  https://cntk.ai/pythondocs/layerref.html#maxpooling-averagepooling\n",
    "\n",
    "# def create_model(features):\n",
    "#     with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "#         model = C.layers.Sequential([\n",
    "#             C.layers.For(range(3), lambda i: [\n",
    "#                 C.layers.Convolution2D(filter_shape=(5,5), \n",
    "#                                      num_filters=[8, 16, 16][i], \n",
    "#                                      pad=True, \n",
    "#                                      strides=[(1,1), (1,1), (2,2)][i]),\n",
    "#                 C.layers.AveragePooling(filter_shape=(2,2),\n",
    "#                                     strides=1, \n",
    "#                                     pad=True)\n",
    "#                 ]),\n",
    "#             C.layers.Dense(num_output_classes, activation=None)\n",
    "#         ])\n",
    "#     return model(features)\n",
    "\n",
    "# Training took 1494.3 sec\n",
    "# Average test error: 28.53% with all pooling being Average Pooling\n",
    "\n",
    "# def create_model(features):\n",
    "\n",
    "#     with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "#         model = C.layers.Sequential([\n",
    "#             C.layers.For(range(3), lambda i: [\n",
    "#                 C.layers.Convolution2D(filter_shape=(5,5), \n",
    "#                                      num_filters=[16, 32, 32][i], \n",
    "#                                      pad=True, \n",
    "#                                      strides=[(1,1), (1,1), (1,1)][i]),\n",
    "#                 C.layers.MaxPooling(filter_shape=(2,2), # 3,3 pooling shape gave 26.9% with conv_third of 1,1 stride\n",
    "#                                     strides=1, \n",
    "#                                     pad=True)\n",
    "#                 ]),\n",
    "#             C.layers.Dense(num_output_classes, activation=None)\n",
    "#         ])\n",
    "#     return model(features)\n",
    "\n",
    "# Training took 5239.7 sec\n",
    "# Average test error: 25.41%\n",
    "\n",
    "\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        model = C.layers.Sequential([\n",
    "            C.layers.For(range(3), lambda i: [\n",
    "                C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                     num_filters=[48, 48, 64][i], \n",
    "                                     pad=True, \n",
    "                                     strides=(1,1),\n",
    "                C.layers.MaxPooling(filter_shape=(2,2),\n",
    "                                    strides=1, \n",
    "                                    pad=True)\n",
    "                ]),\n",
    "            C.layers.Dense(256),\n",
    "            C.layers.Dropout(0.5),\n",
    "            C.layers.Dense(128),\n",
    "            C.layers.Dropout(0.5),\n",
    "            C.layers.Dense(num_output_classes, activation=None)\n",
    "        ])\n",
    "    return model(features)\n",
    "            \n",
    "# 3,3 pooling shape gave 26.9% with conv_third of 1,1 stride\n",
    "# third stride is 2,2:\n",
    "# Training took 12794.1 sec\n",
    "# Average test error: 24.52%\n",
    "\n",
    "# third stride is 1,1\n",
    "# Training took 9812.6 sec\n",
    "# Average test error: 22.35%\n",
    "    \n",
    "# Based on https://arxiv.org/pdf/1706.01509.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Similar to CNTK 102, we minimize the cross-entropy between the label and predicted probability by the network. If this terminology sounds strange to you, please refer to the CNTK 102 for a refresher. Since we are going to build more than one model, we will create a few helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_criterion_function(model, labels):\n",
    "    loss = C.cross_entropy_with_softmax(model, labels)\n",
    "    errs = C.classification_error(model, labels)\n",
    "    return loss, errs # (model, labels) -> (loss, error metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will need a helper function to perform the model training. First let us create additional helper functions that will be needed to visualize different functions associated with training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a utility function to compute the moving average sum.\n",
    "# A more efficient implementation is possible with np.cumsum() function\n",
    "def moving_average(a, w=5):\n",
    "    if len(a) < w:\n",
    "        return a[:]    # Need to send a copy of the array\n",
    "    return [val if idx < w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]\n",
    "\n",
    "\n",
    "# Defines a utility that prints the training progress\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose: \n",
    "            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))\n",
    "        \n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure training\n",
    "\n",
    "In the previous tutorials we have described the concepts of `loss` function, the optimizers or [learners](https://cntk.ai/pythondocs/cntk.learners.html) and the associated machinery needed to train a model. Please refer to earlier tutorials for gaining familiarility with these concepts. In this tutorial, we combine model training and testing in a helper function below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 37917906 parameters in 12 parameter tensors.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the data dimensions\n",
    "height = width = 48\n",
    "input_dim_model = (1, height, width)    # images are 28 x 28 with 1 channel of color (gray)\n",
    "input_dim = height*width*1                # used by readers to treat input data as a vector\n",
    "num_output_classes = 2\n",
    "\n",
    "x = C.input_variable(input_dim_model)\n",
    "y = C.input_variable(num_output_classes)\n",
    "\n",
    "# Initialize the parameters for the trainer\n",
    "minibatch_size = 128\n",
    "num_samples_per_sweep = 13559\n",
    "\n",
    "learning_rate = 0.02\n",
    "\n",
    "# Uncomment below for more detailed logging\n",
    "training_progress_output_freq = 50\n",
    "\n",
    "# Test data for trained model\n",
    "test_minibatch_size = 64\n",
    "num_samples = 1507\n",
    "\n",
    "# Create the model\n",
    "z = create_model(x)\n",
    "\n",
    "# Number of parameters in the network\n",
    "print(C.logging.log_number_of_parameters(z))\n",
    "\n",
    "# # Print the output shapes / parameters of different components\n",
    "# print(\"Output Shape of the first convolution layer:\", z.first_conv.shape)\n",
    "# print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_train(train_reader, model_func, num_sweeps_to_train_with=10):\n",
    "    \n",
    "    # Instantiate the model function; x is the input (feature) variable \n",
    "    # We will scale the input image pixels within 0-1 range by dividing all input value by 255.\n",
    "    model = model_func(x/255)\n",
    "    \n",
    "    # Instantiate the loss and error function\n",
    "    loss, label_error = create_criterion_function(model, y)\n",
    "    \n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "    learner = C.sgd(z.parameters, lr_schedule)\n",
    "    trainer = C.Trainer(z, (loss, label_error), [learner])\n",
    "\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size\n",
    "    \n",
    "    # Map the data streams to the input and labels.\n",
    "    input_map={\n",
    "        y  : train_reader.streams.labels,\n",
    "        x  : train_reader.streams.features\n",
    "    }\n",
    "     \n",
    "    # Start a timer\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_train)):\n",
    "        # Read a mini batch from the training data file\n",
    "        data = train_reader.next_minibatch(minibatch_size, input_map=input_map) \n",
    "        trainer.train_minibatch(data)\n",
    "        print_training_progress(trainer, i, training_progress_output_freq, verbose=1)\n",
    "     \n",
    "    # Print training time\n",
    "    print(\"Training took {:.1f} sec\".format(time.time() - start))\n",
    "\n",
    "    \n",
    "def do_test(test_reader, model_func):\n",
    "    # Test the model\n",
    "\n",
    "    model = model_func(x/255)\n",
    "  \n",
    "    loss, label_error = create_criterion_function(model, y)\n",
    "\n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "    learner = C.sgd(z.parameters, lr_schedule)\n",
    "    trainer = C.Trainer(z, (loss, label_error), [learner])\n",
    "    \n",
    "    test_input_map = {\n",
    "        y  : test_reader.streams.labels,\n",
    "        x  : test_reader.streams.features\n",
    "    }\n",
    "\n",
    "    num_minibatches_to_test = num_samples // test_minibatch_size\n",
    "\n",
    "    test_result = 0.0\n",
    "\n",
    "\n",
    "    for i in range(num_minibatches_to_test):\n",
    "    \n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        # Each data point in the minibatch is a MNIST digit image of 784 dimensions \n",
    "        # with one pixel per dimension that we will encode / decode with the \n",
    "        # trained model.\n",
    "        data = test_reader.next_minibatch(test_minibatch_size, input_map=test_input_map)\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        test_result = test_result + eval_error\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#Run the trainer'></a>\n",
    "### Run the trainer and test model\n",
    "\n",
    "We are now ready to train our convolutional neural net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 0.7007, Error: 53.91%\n",
      "Minibatch: 50, Loss: 0.6966, Error: 44.53%\n",
      "Minibatch: 100, Loss: 0.6851, Error: 44.53%\n",
      "Minibatch: 150, Loss: 0.6883, Error: 44.53%\n",
      "Minibatch: 200, Loss: 0.6482, Error: 37.50%\n",
      "Minibatch: 250, Loss: 0.6340, Error: 36.72%\n",
      "Minibatch: 300, Loss: 0.6110, Error: 30.47%\n",
      "Minibatch: 350, Loss: 0.6312, Error: 41.41%\n",
      "Minibatch: 400, Loss: 0.5706, Error: 25.78%\n",
      "Minibatch: 450, Loss: 0.6528, Error: 32.81%\n",
      "Minibatch: 500, Loss: 0.5372, Error: 29.69%\n",
      "Minibatch: 550, Loss: 0.5035, Error: 25.00%\n",
      "Minibatch: 600, Loss: 0.5371, Error: 28.12%\n",
      "Minibatch: 650, Loss: 0.5166, Error: 25.78%\n",
      "Minibatch: 700, Loss: 0.5583, Error: 29.69%\n",
      "Minibatch: 750, Loss: 0.4932, Error: 27.34%\n",
      "Minibatch: 800, Loss: 0.4999, Error: 14.84%\n",
      "Minibatch: 850, Loss: 0.4959, Error: 23.44%\n",
      "Minibatch: 900, Loss: 0.5125, Error: 31.25%\n",
      "Minibatch: 950, Loss: 0.4189, Error: 20.31%\n",
      "Minibatch: 1000, Loss: 0.4281, Error: 23.44%\n",
      "Minibatch: 1050, Loss: 0.5238, Error: 32.81%\n",
      "Training took 9812.6 sec\n",
      "Average test error: 22.35%\n"
     ]
    }
   ],
   "source": [
    "reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n",
    "do_train(reader_train, z)\n",
    "reader_test = create_reader(test_file, False, input_dim, num_output_classes)\n",
    "do_test(reader_test, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z.save('/data/cnn_maxpool_dropout_emotions.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the average test error is very comparable to our training error indicating that our model has good \"out of sample\" error a.k.a. [generalization error](https://en.wikipedia.org/wiki/Generalization_error). This implies that our model can very effectively deal with previously unseen observations (during the training process). This is key to avoid [overfitting](https://en.wikipedia.org/wiki/Overfitting).\n",
    "\n",
    "Let us check what is the value of some of the network parameters. We will check the bias value of the output dense layer. Previously, it was all 0. Now you see there are non-zero values, indicating that a model parameters were updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation / Prediction\n",
    "We have so far been dealing with aggregate measures of error. Let us now get the probabilities associated with individual data points. For each observation, the `eval` function returns the probability distribution across all the classes. The classifier is trained to recognize digits, hence has 10 classes. First let us route the network output through a `softmax` function. This maps the aggregated activations across the network to probabilities across the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = C.softmax(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us a small minibatch sample from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data for evaluation\n",
    "reader_eval=create_reader('/data/harris_48x48_cntk_text.txt', False, input_dim, num_output_classes)\n",
    "# reader_eval=create_reader(test_file, False, input_dim, num_output_classes)\n",
    "\n",
    "eval_minibatch_size = 2\n",
    "eval_input_map = {x: reader_eval.streams.features, y:reader_eval.streams.labels} \n",
    "\n",
    "data = reader_eval.next_minibatch(eval_minibatch_size, input_map=eval_input_map)\n",
    "\n",
    "img_label = data[y].asarray()\n",
    "img_data = data[x].asarray()\n",
    "\n",
    "# reshape img_data to: M x 1 x 28 x 28 to be compatible with model\n",
    "img_data = np.reshape(img_data, (eval_minibatch_size, 1, 48, 48))\n",
    "\n",
    "predicted_label_prob = [out.eval(img_data[i]) for i in range(len(img_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the index with the maximum value for both predicted as well as the ground truth\n",
    "pred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "gtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    : [0, 1]\n",
      "Predicted: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Label    :\", gtlabel[:25])\n",
    "print(\"Predicted:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD+CAYAAAAalrhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8110c20940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a random image\n",
    "sample_number = 0\n",
    "plt.imshow(img_data[sample_number].reshape(48,48)/255,\n",
    "           interpolation='nearest',\n",
    "           cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "img_gt, img_pred = gtlabel[sample_number], pred[sample_number]\n",
    "print(\"Image Label: \", img_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
